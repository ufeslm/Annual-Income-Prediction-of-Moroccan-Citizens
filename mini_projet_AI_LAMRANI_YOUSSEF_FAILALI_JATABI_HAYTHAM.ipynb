{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Génération de données synthétiques pour la prédiction du revenu annuel\n",
    "\n",
    "Dans cette section, nous générons un dataset synthétique de 40 000 individus pour modéliser le revenu annuel des Marocains. Les variables simulées incluent des informations démographiques (âge, sexe, milieu de résidence), éducatives, professionnelles et patrimoniales.\n",
    "\n",
    "Les étapes principales sont :\n",
    "- Création aléatoire de variables réalistes comme l'âge, le sexe, le niveau d'éducation, l'expérience, etc.\n",
    "- Construction d'une variable cible `revenu_annuel` influencée par différents facteurs socio-économiques avec un ajout de bruit pour simuler la variabilité réelle.\n",
    "- Introduction de valeurs manquantes (5%) dans certaines colonnes pour refléter les données incomplètes du monde réel.\n",
    "- Injection de valeurs aberrantes dans le revenu pour simuler des cas extrêmes.\n",
    "- Création finale d’un DataFrame Pandas, avec exportation au format CSV sous le nom `dataset_revenu_marocains.csv`.\n",
    "\n",
    "Ce dataset servira de base à l'entraînement et à l'évaluation de modèles de machine learning pour la prédiction du revenu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>categorie_age</th>\n",
       "      <th>sexe</th>\n",
       "      <th>milieu</th>\n",
       "      <th>niveau_education</th>\n",
       "      <th>experience</th>\n",
       "      <th>etat_matrimonial</th>\n",
       "      <th>possede_voiture</th>\n",
       "      <th>possede_logement</th>\n",
       "      <th>possede_terrain</th>\n",
       "      <th>socio_pro_group</th>\n",
       "      <th>revenu_annuel</th>\n",
       "      <th>nombre_enfants</th>\n",
       "      <th>charge_parentale</th>\n",
       "      <th>travail_secondaire</th>\n",
       "      <th>colonne_redundante</th>\n",
       "      <th>non_pertinente</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>Sénior</td>\n",
       "      <td>Femme</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Sans niveau</td>\n",
       "      <td>36</td>\n",
       "      <td>Marié</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>17280.125152</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>Âgé</td>\n",
       "      <td>Homme</td>\n",
       "      <td>Urbain</td>\n",
       "      <td>Sans niveau</td>\n",
       "      <td>53</td>\n",
       "      <td>Marié</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>42914.143442</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>Sénior</td>\n",
       "      <td>Femme</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Secondaire</td>\n",
       "      <td>22</td>\n",
       "      <td>Célibataire</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>34253.521168</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>Adulte</td>\n",
       "      <td>Homme</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Fondamental</td>\n",
       "      <td>15</td>\n",
       "      <td>Marié</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>23291.704608</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>Âgé</td>\n",
       "      <td>Homme</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Secondaire</td>\n",
       "      <td>43</td>\n",
       "      <td>Célibataire</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>35530.245679</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25</td>\n",
       "      <td>Jeune</td>\n",
       "      <td>Homme</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Fondamental</td>\n",
       "      <td>4</td>\n",
       "      <td>Célibataire</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>28870.819392</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>38</td>\n",
       "      <td>Adulte</td>\n",
       "      <td>Homme</td>\n",
       "      <td>Urbain</td>\n",
       "      <td>Sans niveau</td>\n",
       "      <td>15</td>\n",
       "      <td>Marié</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>33985.541853</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>56</td>\n",
       "      <td>Sénior</td>\n",
       "      <td>Femme</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Secondaire</td>\n",
       "      <td>35</td>\n",
       "      <td>Marié</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>27741.266025</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36</td>\n",
       "      <td>Adulte</td>\n",
       "      <td>Homme</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Sans niveau</td>\n",
       "      <td>19</td>\n",
       "      <td>Célibataire</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>24213.745398</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>40</td>\n",
       "      <td>Sénior</td>\n",
       "      <td>Homme</td>\n",
       "      <td>Urbain</td>\n",
       "      <td>Sans niveau</td>\n",
       "      <td>20</td>\n",
       "      <td>Marié</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35895.048484</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age categorie_age   sexe  milieu niveau_education  experience  \\\n",
       "0   56        Sénior  Femme   Rural      Sans niveau          36   \n",
       "1   69           Âgé  Homme  Urbain      Sans niveau          53   \n",
       "2   46        Sénior  Femme   Rural       Secondaire          22   \n",
       "3   32        Adulte  Homme   Rural      Fondamental          15   \n",
       "4   60           Âgé  Homme   Rural       Secondaire          43   \n",
       "5   25         Jeune  Homme   Rural      Fondamental           4   \n",
       "6   38        Adulte  Homme  Urbain      Sans niveau          15   \n",
       "7   56        Sénior  Femme   Rural       Secondaire          35   \n",
       "8   36        Adulte  Homme   Rural      Sans niveau          19   \n",
       "9   40        Sénior  Homme  Urbain      Sans niveau          20   \n",
       "\n",
       "  etat_matrimonial  possede_voiture  possede_logement  possede_terrain  \\\n",
       "0            Marié                0                 0                0   \n",
       "1            Marié                0                 1                0   \n",
       "2      Célibataire                1                 1                0   \n",
       "3            Marié                0                 0                0   \n",
       "4      Célibataire                0                 0                0   \n",
       "5      Célibataire                0                 1                0   \n",
       "6            Marié                0                 0                0   \n",
       "7            Marié                0                 0                1   \n",
       "8      Célibataire                1                 0                0   \n",
       "9            Marié                0                 1                0   \n",
       "\n",
       "   socio_pro_group  revenu_annuel  nombre_enfants  charge_parentale  \\\n",
       "0                5   17280.125152               1                 1   \n",
       "1                4   42914.143442               1                 1   \n",
       "2                5   34253.521168               2                 0   \n",
       "3                3   23291.704608               2                 1   \n",
       "4                2   35530.245679               3                 0   \n",
       "5                4   28870.819392               3                 0   \n",
       "6                2   33985.541853               1                 0   \n",
       "7                4   27741.266025               2                 1   \n",
       "8                3   24213.745398               2                 0   \n",
       "9                3   35895.048484               4                 1   \n",
       "\n",
       "   travail_secondaire  colonne_redundante non_pertinente  \n",
       "0                   0                  56            N/A  \n",
       "1                   0                  69            N/A  \n",
       "2                   0                  46            N/A  \n",
       "3                   1                  32            N/A  \n",
       "4                   0                  60            N/A  \n",
       "5                   0                  25            N/A  \n",
       "6                   0                  38            N/A  \n",
       "7                   1                  56            N/A  \n",
       "8                   0                  36            N/A  \n",
       "9                   0                  40            N/A  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Fixer la seed pour la reproductibilité\n",
    "np.random.seed(42)\n",
    "\n",
    "# Nombre d’enregistrements\n",
    "n = 40000\n",
    "\n",
    "# Variables de base simulées\n",
    "ages = np.random.randint(18, 70, size=n)\n",
    "sexes = np.random.choice([\"Homme\", \"Femme\"], size=n, p=[0.55, 0.45])\n",
    "milieux = np.random.choice([\"Urbain\", \"Rural\"], size=n, p=[0.65, 0.35])\n",
    "education_levels = np.random.choice([\"Sans niveau\", \"Fondamental\", \"Secondaire\", \"Supérieur\"], size=n, p=[0.25, 0.35, 0.25, 0.15])\n",
    "experience = np.clip(ages - np.random.randint(16, 25, size=n), 0, None)\n",
    "etat_matrimonial = np.random.choice([\"Célibataire\", \"Marié\", \"Divorcé\", \"Veuf\"], size=n, p=[0.4, 0.45, 0.1, 0.05])\n",
    "possession_voiture = np.random.choice([0, 1], size=n, p=[0.7, 0.3])\n",
    "possession_logement = np.random.choice([0, 1], size=n, p=[0.6, 0.4])\n",
    "possession_terrain = np.random.choice([0, 1], size=n, p=[0.85, 0.15])\n",
    "socio_group = np.random.choice([1, 2, 3, 4, 5, 6], size=n, p=[0.05, 0.15, 0.2, 0.25, 0.2, 0.15])\n",
    "\n",
    "# Variables ajoutées\n",
    "nbr_enfants = np.random.poisson(2, size=n)\n",
    "charge_parentale = np.random.choice([0, 1], size=n, p=[0.6, 0.4])\n",
    "travail_secondaire = np.random.choice([0, 1], size=n, p=[0.85, 0.15])\n",
    "\n",
    "# Catégorie d’âge\n",
    "def categoriser_age(age):\n",
    "    if age < 26:\n",
    "        return \"Jeune\"\n",
    "    elif age < 40:\n",
    "        return \"Adulte\"\n",
    "    elif age < 60:\n",
    "        return \"Sénior\"\n",
    "    else:\n",
    "        return \"Âgé\"\n",
    "\n",
    "categorie_age = np.array([categoriser_age(a) for a in ages])\n",
    "\n",
    "# Génération du revenu avec bruit\n",
    "base_revenu = (\n",
    "    12000 +\n",
    "    (ages * 100) +\n",
    "    (experience * 150) +\n",
    "    (np.where(sexes == \"Homme\", 2000, -1000)) +\n",
    "    (np.where(milieux == \"Urbain\", 6000, -3000)) +\n",
    "    (np.array([{\"Sans niveau\": 0, \"Fondamental\": 2000, \"Secondaire\": 5000, \"Supérieur\": 10000}[e] for e in education_levels])) +\n",
    "    (np.array([8000 - g * 1000 for g in socio_group])) +\n",
    "    (possession_voiture * 3000 + possession_logement * 5000 + possession_terrain * 2000)\n",
    ")\n",
    "\n",
    "revenus = base_revenu + np.random.normal(0, 3000, size=n)\n",
    "revenus = np.clip(revenus, 2000, None)  # Minimum revenu\n",
    "\n",
    "# Injecter valeurs manquantes (5% aléatoirement)\n",
    "for col in [\"education_levels\", \"etat_matrimonial\", \"revenus\"]:\n",
    "    mask = np.random.rand(n) < 0.05\n",
    "    vars()[col][mask] = None\n",
    "\n",
    "# Créer le DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"age\": ages,\n",
    "    \"categorie_age\": categorie_age,\n",
    "    \"sexe\": sexes,\n",
    "    \"milieu\": milieux,\n",
    "    \"niveau_education\": education_levels,\n",
    "    \"experience\": experience,\n",
    "    \"etat_matrimonial\": etat_matrimonial,\n",
    "    \"possede_voiture\": possession_voiture,\n",
    "    \"possede_logement\": possession_logement,\n",
    "    \"possede_terrain\": possession_terrain,\n",
    "    \"socio_pro_group\": socio_group,\n",
    "    \"revenu_annuel\": revenus,\n",
    "    \"nombre_enfants\": nbr_enfants,\n",
    "    \"charge_parentale\": charge_parentale,\n",
    "    \"travail_secondaire\": travail_secondaire,\n",
    "    \"colonne_redundante\": ages,  # Redondante\n",
    "    \"non_pertinente\": \"N/A\"  # Non pertinente\n",
    "})\n",
    "\n",
    "# Injecter quelques valeurs aberrantes\n",
    "df.loc[df.sample(frac=0.005).index, \"revenu_annuel\"] *= 5\n",
    "\n",
    "# Sauvegarder le CSV\n",
    "csv_path = \"dataset_revenu_marocains.csv\"\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "csv_path\n",
    "# Aperçu des 10 premières lignes\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📋 Exploration initiale du dataset\n",
    "\n",
    "Dans cette section, nous effectuons une première exploration du dataset généré afin de mieux comprendre sa structure et son contenu. Les actions réalisées sont les suivantes :\n",
    "\n",
    "- 📊 Affichage du **nombre total d'observations** (lignes) et de **variables** (colonnes).\n",
    "- 🔍 Inspection des **types de données** (numériques, catégorielles, booléennes, etc.) pour chaque colonne.\n",
    "- 📈 Génération de **statistiques descriptives** pour les variables numériques (moyenne, écart-type, min, max, quartiles).\n",
    "- 📊 Génération de statistiques pour les **variables catégorielles** (nombre de valeurs uniques, valeur la plus fréquente, fréquence associée).\n",
    "\n",
    "Ces étapes permettent d’identifier rapidement les variables clés, les éventuelles anomalies, et de poser les bases pour les étapes de nettoyage et de visualisation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T11:14:34.252826Z",
     "iopub.status.busy": "2025-05-14T11:14:34.252460Z",
     "iopub.status.idle": "2025-05-14T11:14:34.364768Z",
     "shell.execute_reply": "2025-05-14T11:14:34.363646Z",
     "shell.execute_reply.started": "2025-05-14T11:14:34.252779Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Nombre d’instances : 40000\n",
      "✅ Nombre de colonnes : 17\n",
      "\n",
      "📌 Types de données :\n",
      "age                     int64\n",
      "categorie_age          object\n",
      "sexe                   object\n",
      "milieu                 object\n",
      "niveau_education       object\n",
      "experience              int64\n",
      "etat_matrimonial       object\n",
      "possede_voiture         int64\n",
      "possede_logement        int64\n",
      "possede_terrain         int64\n",
      "socio_pro_group         int64\n",
      "revenu_annuel         float64\n",
      "nombre_enfants          int64\n",
      "charge_parentale        int64\n",
      "travail_secondaire      int64\n",
      "colonne_redundante      int64\n",
      "non_pertinente         object\n",
      "dtype: object\n",
      "\n",
      "📌 Statistiques descriptives (valeurs numériques) :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>experience</th>\n",
       "      <th>possede_voiture</th>\n",
       "      <th>possede_logement</th>\n",
       "      <th>possede_terrain</th>\n",
       "      <th>socio_pro_group</th>\n",
       "      <th>revenu_annuel</th>\n",
       "      <th>nombre_enfants</th>\n",
       "      <th>charge_parentale</th>\n",
       "      <th>travail_secondaire</th>\n",
       "      <th>colonne_redundante</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>37993.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>43.491175</td>\n",
       "      <td>23.628675</td>\n",
       "      <td>0.300850</td>\n",
       "      <td>0.399925</td>\n",
       "      <td>0.148850</td>\n",
       "      <td>3.837275</td>\n",
       "      <td>34881.745127</td>\n",
       "      <td>2.005275</td>\n",
       "      <td>0.401550</td>\n",
       "      <td>0.150975</td>\n",
       "      <td>43.491175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.976835</td>\n",
       "      <td>14.989533</td>\n",
       "      <td>0.458633</td>\n",
       "      <td>0.489889</td>\n",
       "      <td>0.355945</td>\n",
       "      <td>1.419999</td>\n",
       "      <td>12872.564645</td>\n",
       "      <td>1.420070</td>\n",
       "      <td>0.490218</td>\n",
       "      <td>0.358029</td>\n",
       "      <td>14.976835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3975.246759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28701.094523</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>43.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>34273.345282</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>39797.197853</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>69.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>289898.277678</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>69.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age    experience  possede_voiture  possede_logement  \\\n",
       "count  40000.000000  40000.000000     40000.000000      40000.000000   \n",
       "mean      43.491175     23.628675         0.300850          0.399925   \n",
       "std       14.976835     14.989533         0.458633          0.489889   \n",
       "min       18.000000      0.000000         0.000000          0.000000   \n",
       "25%       31.000000     11.000000         0.000000          0.000000   \n",
       "50%       43.000000     23.000000         0.000000          0.000000   \n",
       "75%       56.000000     37.000000         1.000000          1.000000   \n",
       "max       69.000000     53.000000         1.000000          1.000000   \n",
       "\n",
       "       possede_terrain  socio_pro_group  revenu_annuel  nombre_enfants  \\\n",
       "count     40000.000000     40000.000000   37993.000000    40000.000000   \n",
       "mean          0.148850         3.837275   34881.745127        2.005275   \n",
       "std           0.355945         1.419999   12872.564645        1.420070   \n",
       "min           0.000000         1.000000    3975.246759        0.000000   \n",
       "25%           0.000000         3.000000   28701.094523        1.000000   \n",
       "50%           0.000000         4.000000   34273.345282        2.000000   \n",
       "75%           0.000000         5.000000   39797.197853        3.000000   \n",
       "max           1.000000         6.000000  289898.277678        9.000000   \n",
       "\n",
       "       charge_parentale  travail_secondaire  colonne_redundante  \n",
       "count      40000.000000        40000.000000        40000.000000  \n",
       "mean           0.401550            0.150975           43.491175  \n",
       "std            0.490218            0.358029           14.976835  \n",
       "min            0.000000            0.000000           18.000000  \n",
       "25%            0.000000            0.000000           31.000000  \n",
       "50%            0.000000            0.000000           43.000000  \n",
       "75%            1.000000            0.000000           56.000000  \n",
       "max            1.000000            1.000000           69.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📌 Statistiques descriptives (valeurs catégorielles) :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categorie_age</th>\n",
       "      <th>sexe</th>\n",
       "      <th>milieu</th>\n",
       "      <th>niveau_education</th>\n",
       "      <th>etat_matrimonial</th>\n",
       "      <th>non_pertinente</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>40000</td>\n",
       "      <td>40000</td>\n",
       "      <td>40000</td>\n",
       "      <td>40000</td>\n",
       "      <td>40000</td>\n",
       "      <td>40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Sénior</td>\n",
       "      <td>Homme</td>\n",
       "      <td>Urbain</td>\n",
       "      <td>Fondamental</td>\n",
       "      <td>Marié</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>15325</td>\n",
       "      <td>22026</td>\n",
       "      <td>25987</td>\n",
       "      <td>13223</td>\n",
       "      <td>17045</td>\n",
       "      <td>40000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       categorie_age   sexe  milieu niveau_education etat_matrimonial  \\\n",
       "count          40000  40000   40000            40000            40000   \n",
       "unique             4      2       2                5                5   \n",
       "top           Sénior  Homme  Urbain      Fondamental            Marié   \n",
       "freq           15325  22026   25987            13223            17045   \n",
       "\n",
       "       non_pertinente  \n",
       "count           40000  \n",
       "unique              1  \n",
       "top               N/A  \n",
       "freq            40000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 📊 Volume et dimensions\n",
    "print(f\"✅ Nombre d’instances : {df.shape[0]}\")\n",
    "print(f\"✅ Nombre de colonnes : {df.shape[1]}\")\n",
    "\n",
    "# 🔍 Types des données\n",
    "print(\"\\n📌 Types de données :\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# 📈 Statistiques descriptives globales\n",
    "print(\"\\n📌 Statistiques descriptives (valeurs numériques) :\")\n",
    "display(df.describe())\n",
    "\n",
    "print(\"\\n📌 Statistiques descriptives (valeurs catégorielles) :\")\n",
    "display(df.describe(include='object'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T11:14:34.971692Z",
     "iopub.status.busy": "2025-05-14T11:14:34.971410Z",
     "iopub.status.idle": "2025-05-14T11:14:39.027240Z",
     "shell.execute_reply": "2025-05-14T11:14:39.025942Z",
     "shell.execute_reply.started": "2025-05-14T11:14:34.971671Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sweetviz in /usr/local/lib/python3.11/dist-packages (2.3.1)\n",
      "Requirement already satisfied: pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3 in /usr/local/lib/python3.11/dist-packages (from sweetviz) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from sweetviz) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.1.3 in /usr/local/lib/python3.11/dist-packages (from sweetviz) (3.7.2)\n",
      "Requirement already satisfied: tqdm>=4.43.0 in /usr/local/lib/python3.11/dist-packages (from sweetviz) (4.67.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from sweetviz) (1.15.2)\n",
      "Requirement already satisfied: jinja2>=2.11.1 in /usr/local/lib/python3.11/dist-packages (from sweetviz) (3.1.6)\n",
      "Requirement already satisfied: importlib-resources>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from sweetviz) (6.5.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=2.11.1->sweetviz) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.1.3->sweetviz) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.1.3->sweetviz) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.1.3->sweetviz) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.1.3->sweetviz) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.1.3->sweetviz) (25.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.1.3->sweetviz) (11.1.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.1.3->sweetviz) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.1.3->sweetviz) (2.9.0.post0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.16.0->sweetviz) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.16.0->sweetviz) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.16.0->sweetviz) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.16.0->sweetviz) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.16.0->sweetviz) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.16.0->sweetviz) (2.4.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3->sweetviz) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3->sweetviz) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.1.3->sweetviz) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.16.0->sweetviz) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.16.0->sweetviz) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.16.0->sweetviz) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.16.0->sweetviz) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.16.0->sweetviz) (2024.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sweetviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🤖 Analyse exploratoire automatisée avec Sweetviz\n",
    "\n",
    "Pour compléter l’exploration manuelle du dataset, nous utilisons **Sweetviz**, une bibliothèque Python qui génère automatiquement un rapport visuel interactif sur les données.\n",
    "\n",
    "L’analyse comprend :\n",
    "- Les distributions des variables numériques et catégorielles.\n",
    "- La détection des valeurs manquantes.\n",
    "- Les corrélations entre variables.\n",
    "- Les comparaisons entre classes si une variable cible est définie (dans notre cas, ce sera utile plus tard).\n",
    "\n",
    "Un fichier HTML nommé `rapport_complet_sweetviz.html` est généré. Il peut être ouvert dans un navigateur pour explorer facilement les caractéristiques du dataset.\n",
    "\n",
    "> ⚠️ Assurez-vous que le fichier est bien généré dans le même répertoire que le notebook pour pouvoir le consulter sans problème.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T11:14:39.029490Z",
     "iopub.status.busy": "2025-05-14T11:14:39.029157Z",
     "iopub.status.idle": "2025-05-14T11:14:51.376470Z",
     "shell.execute_reply": "2025-05-14T11:14:51.374862Z",
     "shell.execute_reply.started": "2025-05-14T11:14:39.029459Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2120515f80834765b37b8576a588aa92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                                             |          | [  0%]   00:00 -> (? left)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report rapport_complet_sweetviz.html was generated! NOTEBOOK/COLAB USERS: the web browser MAY not pop up, regardless, the report IS saved in your notebook/colab files.\n",
      "✅ Rapport Sweetviz généré : rapport_complet_sweetviz.html\n"
     ]
    }
   ],
   "source": [
    "# 📊 Analyse exploratoire automatisée avec Sweetviz\n",
    "import sweetviz as sv\n",
    "\n",
    "rapport = sv.analyze(df)\n",
    "rapport.show_html(\"rapport_complet_sweetviz.html\")\n",
    "\n",
    "print(\"✅ Rapport Sweetviz généré : rapport_complet_sweetviz.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧼 Nettoyage des données\n",
    "\n",
    "Avant d'entraîner un modèle de machine learning, il est essentiel de nettoyer le dataset afin d'améliorer la qualité des données et la fiabilité des résultats.\n",
    "\n",
    "Les étapes suivantes sont effectuées :\n",
    "\n",
    "1. **Suppression des lignes avec un revenu manquant** (`revenu_annuel`) : comme cette variable est notre cible pour la prédiction, les lignes sans cette information sont retirées.\n",
    "2. **Suppression des doublons** : les entrées dupliquées sont supprimées pour éviter les biais dans l’analyse ou l'entraînement du modèle.\n",
    "3. **Correction des valeurs aberrantes dans le revenu annuel** :  \n",
    "   - Utilisation de la méthode de l'écart interquartile (IQR) pour détecter les revenus excessivement élevés.\n",
    "   - Les valeurs au-dessus de `Q3 + 3*IQR` sont plafonnées à cette limite supérieure.\n",
    "\n",
    "Ces opérations permettent d’assurer la **cohérence**, la **qualité** et la **pertinence statistique** des données.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T11:14:51.378279Z",
     "iopub.status.busy": "2025-05-14T11:14:51.377708Z",
     "iopub.status.idle": "2025-05-14T11:14:51.453298Z",
     "shell.execute_reply": "2025-05-14T11:14:51.452032Z",
     "shell.execute_reply.started": "2025-05-14T11:14:51.378250Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Doublons supprimés : 0\n",
      "✅ Valeurs aberrantes corrigées : 190\n"
     ]
    }
   ],
   "source": [
    "# 🧼 6.2 – Nettoyage des données\n",
    "\n",
    "# 1️⃣ Supprimer les lignes avec un revenu manquant\n",
    "df = df[df[\"revenu_annuel\"].notna()].copy()\n",
    "\n",
    "# 2️⃣ Supprimer les doublons\n",
    "initial_count = df.shape[0]\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(f\"✅ Doublons supprimés : {initial_count - df.shape[0]}\")\n",
    "\n",
    "# 3️⃣ Correction des valeurs aberrantes sur revenu_annuel\n",
    "q1 = df[\"revenu_annuel\"].quantile(0.25)\n",
    "q3 = df[\"revenu_annuel\"].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "upper_bound = q3 + 3 * iqr\n",
    "\n",
    "aberrant_mask = df[\"revenu_annuel\"] > upper_bound\n",
    "nb_aberrants = aberrant_mask.sum()\n",
    "df.loc[aberrant_mask, \"revenu_annuel\"] = upper_bound\n",
    "\n",
    "print(f\"✅ Valeurs aberrantes corrigées : {nb_aberrants}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔁 Transformation des données avec pipelines\n",
    "\n",
    "Dans cette section, nous préparons les données pour l'entraînement des modèles de machine learning. Cela inclut la suppression de variables inutiles, la séparation des variables explicatives de la variable cible, ainsi que la définition d’un pipeline de transformation.\n",
    "\n",
    "### Étapes effectuées :\n",
    "\n",
    "1. **Suppression des colonnes inutiles** :\n",
    "   - `colonne_redundante` et `non_pertinente` sont supprimées car elles n’apportent aucune information pertinente pour la modélisation.\n",
    "\n",
    "2. **Séparation des variables** :\n",
    "   - `X` contient les variables explicatives.\n",
    "   - `y` contient la variable cible : `revenu_annuel`.\n",
    "\n",
    "3. **Identification des types de variables** :\n",
    "   - Les colonnes numériques et catégorielles sont automatiquement détectées pour appliquer des traitements adaptés.\n",
    "\n",
    "4. **Construction des pipelines** :\n",
    "   - 🧮 Pour les **variables numériques** : imputation des valeurs manquantes par la médiane + standardisation.\n",
    "   - 🏷️ Pour les **variables catégorielles** : imputation par la modalité la plus fréquente + encodage one-hot (avec gestion des modalités inconnues).\n",
    "\n",
    "L’ensemble est intégré dans un `ColumnTransformer` pour garantir une transformation cohérente et automatisée des données en amont de la modélisation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T11:14:57.761104Z",
     "iopub.status.busy": "2025-05-14T11:14:57.760592Z",
     "iopub.status.idle": "2025-05-14T11:14:57.932877Z",
     "shell.execute_reply": "2025-05-14T11:14:57.931176Z",
     "shell.execute_reply.started": "2025-05-14T11:14:57.761076Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Colonnes redondantes et non pertinentes supprimées.\n",
      "✅ Pipeline de transformation prêt.\n"
     ]
    }
   ],
   "source": [
    "# 🔁 6.3 – Transformation des données\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# 1️⃣ Suppression des colonnes redondantes et non pertinentes\n",
    "df.drop(columns=[\"colonne_redundante\", \"non_pertinente\"], inplace=True, errors=\"ignore\")\n",
    "print(\"✅ Colonnes redondantes et non pertinentes supprimées.\")\n",
    "\n",
    "# 2️⃣ Séparer X et y\n",
    "X = df.drop(\"revenu_annuel\", axis=1)\n",
    "y = df[\"revenu_annuel\"]\n",
    "\n",
    "# 3️⃣ Identifier les colonnes numériques et catégorielles\n",
    "numerical_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "categorical_cols = X.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "# 4️⃣ Construire le pipeline de transformation\n",
    "num_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor_final = ColumnTransformer(transformers=[\n",
    "    (\"num\", num_pipeline, numerical_cols),\n",
    "    (\"cat\", cat_pipeline, categorical_cols)\n",
    "])\n",
    "\n",
    "print(\"✅ Pipeline de transformation prêt.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✂️ Séparation des données en ensembles d'entraînement et de test\n",
    "\n",
    "Avant d'entraîner un modèle, il est essentiel de diviser le dataset en deux sous-ensembles distincts :\n",
    "\n",
    "- **Ensemble d'entraînement (train)** : utilisé pour ajuster les paramètres du modèle.\n",
    "- **Ensemble de test (test)** : utilisé pour évaluer la performance du modèle sur des données jamais vues.\n",
    "\n",
    "Dans notre cas :\n",
    "- 70 % des données sont utilisées pour l'entraînement.\n",
    "- 30 % sont réservées pour le test.\n",
    "- La séparation est **aléatoire mais reproductible** grâce à l’argument `random_state=42`.\n",
    "\n",
    "Cette séparation permet une **évaluation fiable** de la capacité du modèle à généraliser à de nouvelles données.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T11:15:02.443714Z",
     "iopub.status.busy": "2025-05-14T11:15:02.443403Z",
     "iopub.status.idle": "2025-05-14T11:15:02.468504Z",
     "shell.execute_reply": "2025-05-14T11:15:02.466955Z",
     "shell.execute_reply.started": "2025-05-14T11:15:02.443693Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Séparation des données effectuée :\n",
      "   ➤ Train : 26595 lignes\n",
      "   ➤ Test  : 11398 lignes\n"
     ]
    }
   ],
   "source": [
    "# ✂️ 6.4 – Séparation des données\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 70% train, 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"✅ Séparation des données effectuée :\")\n",
    "print(f\"   ➤ Train : {X_train.shape[0]} lignes\")\n",
    "print(f\"   ➤ Test  : {X_test.shape[0]} lignes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧠 Modélisation et recherche d’hyperparamètres\n",
    "\n",
    "Nous testons plusieurs modèles de régression afin de prédire le **revenu annuel**. Pour chaque modèle, nous utilisons un pipeline complet incluant la transformation des données (`preprocessor_final`) et la recherche des **meilleurs hyperparamètres** à l’aide de `RandomizedSearchCV`.\n",
    "\n",
    "### Modèles évalués :\n",
    "- 🔹 `LinearRegression` : modèle de base, sans hyperparamètres.\n",
    "- 🌲 `DecisionTreeRegressor` : arbre de décision avec recherche sur la profondeur, le critère, etc.\n",
    "- 🌳 `RandomForestRegressor` : forêt aléatoire avec ajustement du nombre d’arbres et de leur profondeur.\n",
    "- 🔺 `GradientBoostingRegressor` : boosting par gradient avec tuning du taux d’apprentissage, du nombre d’arbres, etc.\n",
    "- 🧠 `MLPRegressor` : réseau de neurones avec arrêt anticipé et ajustement de plusieurs paramètres (couches, activation, taux d’apprentissage...).\n",
    "\n",
    "### Méthodologie :\n",
    "- Utilisation de `RandomizedSearchCV` avec 3 **folds** pour validation croisée.\n",
    "- **Score d’optimisation** : `R²` sur les données de validation.\n",
    "- **Évaluation finale** sur l’ensemble de test à l’aide des métriques :\n",
    "  - R² (coefficient de détermination)\n",
    "  - MAE (erreur absolue moyenne)\n",
    "  - RMSE (racine de l’erreur quadratique moyenne)\n",
    "\n",
    "À la fin, un **résumé comparatif** présente les performances et les meilleurs paramètres pour chaque modèle.\n",
    "\n",
    "> ⚙️ N_iter est fixé à 5 pour accélérer les recherches, mais il peut être augmenté pour améliorer les résultats.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T14:21:35.459854Z",
     "iopub.status.busy": "2025-05-14T14:21:35.459339Z",
     "iopub.status.idle": "2025-05-14T14:44:02.968704Z",
     "shell.execute_reply": "2025-05-14T14:44:02.967504Z",
     "shell.execute_reply.started": "2025-05-14T14:21:35.459823Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Entraînement (RandomizedSearchCV) pour : LinearRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:305: UserWarning: The total space of parameters 1 is smaller than n_iter=5. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Résultats :\n",
      "   ➤ R2 (test)  : 0.7663\n",
      "   ➤ MAE (test) : 2608.12\n",
      "   ➤ RMSE (test): 4069.83\n",
      "   ➤ Meilleurs hyperparamètres : {}\n",
      "🔄 Entraînement (RandomizedSearchCV) pour : DecisionTreeRegressor\n",
      "📊 Résultats :\n",
      "   ➤ R2 (test)  : 0.6982\n",
      "   ➤ MAE (test) : 3070.21\n",
      "   ➤ RMSE (test): 4624.90\n",
      "   ➤ Meilleurs hyperparamètres : {'decisiontreeregressor__min_samples_split': 2, 'decisiontreeregressor__max_depth': 10, 'decisiontreeregressor__criterion': 'absolute_error'}\n",
      "🔄 Entraînement (RandomizedSearchCV) pour : RandomForestRegressor\n",
      "📊 Résultats :\n",
      "   ➤ R2 (test)  : 0.7203\n",
      "   ➤ MAE (test) : 2921.76\n",
      "   ➤ RMSE (test): 4452.03\n",
      "   ➤ Meilleurs hyperparamètres : {'randomforestregressor__n_estimators': 200, 'randomforestregressor__max_depth': 15, 'randomforestregressor__criterion': 'squared_error'}\n",
      "🔄 Entraînement (RandomizedSearchCV) pour : GradientBoostingRegressor\n",
      "📊 Résultats :\n",
      "   ➤ R2 (test)  : 0.7623\n",
      "   ➤ MAE (test) : 2645.78\n",
      "   ➤ RMSE (test): 4104.41\n",
      "   ➤ Meilleurs hyperparamètres : {'gradientboostingregressor__subsample': 0.8, 'gradientboostingregressor__n_estimators': 100, 'gradientboostingregressor__loss': 'squared_error', 'gradientboostingregressor__learning_rate': 0.1}\n",
      "🔄 Entraînement (RandomizedSearchCV) pour : MLPRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Résultats :\n",
      "   ➤ R2 (test)  : 0.7331\n",
      "   ➤ MAE (test) : 2879.04\n",
      "   ➤ RMSE (test): 4348.77\n",
      "   ➤ Meilleurs hyperparamètres : {'mlpregressor__solver': 'adam', 'mlpregressor__max_iter': 200, 'mlpregressor__learning_rate_init': 0.1, 'mlpregressor__learning_rate': 'adaptive', 'mlpregressor__hidden_layer_sizes': (50,), 'mlpregressor__alpha': 0.01, 'mlpregressor__activation': 'tanh'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modèle</th>\n",
       "      <th>R2 (test)</th>\n",
       "      <th>MAE (test)</th>\n",
       "      <th>RMSE (test)</th>\n",
       "      <th>Meilleurs paramètres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.766278</td>\n",
       "      <td>2608.115165</td>\n",
       "      <td>4069.831167</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.762289</td>\n",
       "      <td>2645.779093</td>\n",
       "      <td>4104.411564</td>\n",
       "      <td>{'gradientboostingregressor__subsample': 0.8, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>0.733142</td>\n",
       "      <td>2879.037074</td>\n",
       "      <td>4348.774920</td>\n",
       "      <td>{'mlpregressor__solver': 'adam', 'mlpregressor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.720319</td>\n",
       "      <td>2921.762837</td>\n",
       "      <td>4452.028848</td>\n",
       "      <td>{'randomforestregressor__n_estimators': 200, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>0.698177</td>\n",
       "      <td>3070.214191</td>\n",
       "      <td>4624.904614</td>\n",
       "      <td>{'decisiontreeregressor__min_samples_split': 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Modèle  R2 (test)   MAE (test)  RMSE (test)  \\\n",
       "0           LinearRegression   0.766278  2608.115165  4069.831167   \n",
       "3  GradientBoostingRegressor   0.762289  2645.779093  4104.411564   \n",
       "4               MLPRegressor   0.733142  2879.037074  4348.774920   \n",
       "2      RandomForestRegressor   0.720319  2921.762837  4452.028848   \n",
       "1      DecisionTreeRegressor   0.698177  3070.214191  4624.904614   \n",
       "\n",
       "                                Meilleurs paramètres  \n",
       "0                                                 {}  \n",
       "3  {'gradientboostingregressor__subsample': 0.8, ...  \n",
       "4  {'mlpregressor__solver': 'adam', 'mlpregressor...  \n",
       "2  {'randomforestregressor__n_estimators': 200, '...  \n",
       "1  {'decisiontreeregressor__min_samples_split': 2...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Modèles et hyperparamètres\n",
    "models = {\n",
    "    \"LinearRegression\": {\n",
    "        \"estimator\": make_pipeline(preprocessor_final, LinearRegression()),\n",
    "        \"params\": {}\n",
    "    },\n",
    "    \"DecisionTreeRegressor\": {\n",
    "        \"estimator\": make_pipeline(preprocessor_final, DecisionTreeRegressor(random_state=42)),\n",
    "        \"params\": {\n",
    "            \"decisiontreeregressor__criterion\": [\"squared_error\", \"absolute_error\"],\n",
    "            \"decisiontreeregressor__max_depth\": [None, 5, 6, 7, 10],\n",
    "            \"decisiontreeregressor__min_samples_split\": [2, 3, 4, 5, 10]\n",
    "        }\n",
    "    },\n",
    "    \"RandomForestRegressor\": {\n",
    "        \"estimator\": make_pipeline(preprocessor_final, RandomForestRegressor(random_state=42)),\n",
    "        \"params\": {\n",
    "            \"randomforestregressor__n_estimators\": [50, 100, 150, 200],\n",
    "            \"randomforestregressor__criterion\": [\"squared_error\", \"absolute_error\"],\n",
    "            \"randomforestregressor__max_depth\": [None, 5, 10, 15, 20]\n",
    "        }\n",
    "    },\n",
    "    \"GradientBoostingRegressor\": {\n",
    "        \"estimator\": make_pipeline(preprocessor_final, GradientBoostingRegressor(random_state=42)),\n",
    "        \"params\": {\n",
    "            \"gradientboostingregressor__loss\": [\"squared_error\", \"absolute_error\"],\n",
    "            \"gradientboostingregressor__learning_rate\": [0.01, 0.1, 0.2],\n",
    "            \"gradientboostingregressor__n_estimators\": [100, 200, 300],\n",
    "            \"gradientboostingregressor__subsample\": [0.5, 0.8, 1]\n",
    "        }\n",
    "    },\n",
    "    \"MLPRegressor\": {\n",
    "    \"estimator\": make_pipeline(\n",
    "        preprocessor_final,\n",
    "        MLPRegressor(\n",
    "            random_state=42,\n",
    "            early_stopping=True,     # ✅ stoppe si pas d’amélioration\n",
    "            tol=1e-4,                # ✅ tolérance plus stricte\n",
    "            max_fun=15000            # ✅ empêche trop d’appels internes\n",
    "        )\n",
    "    ),\n",
    "    \"params\": {\n",
    "        \"mlpregressor__hidden_layer_sizes\": [(50,), (100,), (100, 50), (100, 100)],\n",
    "        \"mlpregressor__activation\": [\"relu\", \"tanh\", \"logistic\"],\n",
    "        \"mlpregressor__solver\": [\"adam\", \"sgd\"],\n",
    "        \"mlpregressor__alpha\": [0.0001, 0.001, 0.01],\n",
    "        \"mlpregressor__learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "        \"mlpregressor__learning_rate_init\": [0.001, 0.01, 0.1],\n",
    "        \"mlpregressor__max_iter\": [100, 200, 300]\n",
    "    }\n",
    "}\n",
    "}\n",
    "\n",
    "# Résultats\n",
    "results = []\n",
    "\n",
    "for name, config in models.items():\n",
    "    print(f\"🔄 Entraînement (RandomizedSearchCV) pour : {name}\")\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=config[\"estimator\"],\n",
    "        param_distributions=config[\"params\"],\n",
    "        n_iter=5,  # 🟡 Tu peux ajuster à 5 ou 3 si c’est encore lent\n",
    "        scoring=\"r2\",\n",
    "        cv=3,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    search.fit(X_train, y_train)\n",
    "    y_pred = search.predict(X_test)\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(\"📊 Résultats :\")\n",
    "    print(f\"   ➤ R2 (test)  : {r2:.4f}\")\n",
    "    print(f\"   ➤ MAE (test) : {mae:.2f}\")\n",
    "    print(f\"   ➤ RMSE (test): {rmse:.2f}\")\n",
    "    print(f\"   ➤ Meilleurs hyperparamètres : {search.best_params_}\")\n",
    "    results.append({\n",
    "        \"Modèle\": name,\n",
    "        \"Meilleurs paramètres\": search.best_params_,\n",
    "        \"R2 (validation)\": search.best_score_,\n",
    "        \"MAE (test)\": mae,\n",
    "        \"RMSE (test)\": rmse,\n",
    "        \"R2 (test)\": r2,\n",
    "        \"Pipeline\": search.best_estimator_\n",
    "    })\n",
    "\n",
    "# Résumé des résultats\n",
    "results_df = pd.DataFrame(results).sort_values(by=\"R2 (test)\", ascending=False)\n",
    "results_df[[\"Modèle\", \"R2 (test)\", \"MAE (test)\", \"RMSE (test)\", \"Meilleurs paramètres\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✅ Test final du meilleur modèle\n",
    "\n",
    "Après l’évaluation de plusieurs modèles, nous sélectionnons **celui qui présente le meilleur score R²** sur les données de test.\n",
    "\n",
    "### Étapes réalisées :\n",
    "1. **Identification automatique** du modèle le plus performant (`best_model`) selon le R².\n",
    "2. **Prédiction** sur l’ensemble de test (`X_test`) avec ce modèle.\n",
    "3. **Évaluation finale** à l’aide des métriques :\n",
    "   - MAE (Erreur absolue moyenne)\n",
    "   - RMSE (Racine de l’erreur quadratique moyenne)\n",
    "   - R² (Coefficient de détermination)\n",
    "\n",
    "> 🎯 Ce test final permet de valider que le modèle sélectionné est capable de **généraliser correctement** à de nouvelles données.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T14:46:34.528192Z",
     "iopub.status.busy": "2025-05-14T14:46:34.527854Z",
     "iopub.status.idle": "2025-05-14T14:46:34.583918Z",
     "shell.execute_reply": "2025-05-14T14:46:34.581859Z",
     "shell.execute_reply.started": "2025-05-14T14:46:34.528173Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Test du modèle sélectionné : LinearRegression\n",
      "📊 Résultats finaux du modèle sélectionné :\n",
      "   ➤ MAE  : 2608.12\n",
      "   ➤ RMSE : 4069.83\n",
      "   ➤ R²   : 0.7663\n"
     ]
    }
   ],
   "source": [
    "# 6.6 – Test final du meilleur modèle\n",
    "\n",
    "# 1️⃣ Identifier le modèle le plus performant (meilleur R²)\n",
    "best_model_info = results_df.sort_values(by=\"R2 (test)\", ascending=False).iloc[0]\n",
    "best_model_name = best_model_info[\"Modèle\"]\n",
    "best_model = best_model_info[\"Pipeline\"]\n",
    "\n",
    "print(f\"\\n✅ Test du modèle sélectionné : {best_model_name}\")\n",
    "\n",
    "# 2️⃣ Prédiction sur X_test\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# 3️⃣ Évaluation finale\n",
    "mae_final = mean_absolute_error(y_test, y_pred)\n",
    "rmse_final = mean_squared_error(y_test, y_pred, squared=False)\n",
    "r2_final = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"📊 Résultats finaux du modèle sélectionné :\")\n",
    "print(f\"   ➤ MAE  : {mae_final:.2f}\")\n",
    "print(f\"   ➤ RMSE : {rmse_final:.2f}\")\n",
    "print(f\"   ➤ R²   : {r2_final:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💾 Sauvegarde des meilleurs modèles\n",
    "\n",
    "Afin de pouvoir **réutiliser les modèles sans devoir les réentraîner**, nous sauvegardons les **3 meilleurs modèles** (selon leur score R² sur l’ensemble de test) au format `.joblib`.\n",
    "\n",
    "### Pourquoi sauvegarder les modèles ?\n",
    "- Pour une utilisation dans une **application web** ou une **API de prédiction**.\n",
    "- Pour **partager** le modèle avec d'autres utilisateurs.\n",
    "- Pour **gagner du temps** lors de futures prédictions.\n",
    "\n",
    "> 📂 Les fichiers générés peuvent ensuite être rechargés avec `joblib.load(\"nom_du_fichier.joblib\")`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T14:52:40.662427Z",
     "iopub.status.busy": "2025-05-14T14:52:40.662039Z",
     "iopub.status.idle": "2025-05-14T14:52:40.696224Z",
     "shell.execute_reply": "2025-05-14T14:52:40.694885Z",
     "shell.execute_reply.started": "2025-05-14T14:52:40.662405Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LinearRegression', 'linearregression_model.joblib'),\n",
       " ('GradientBoostingRegressor', 'gradientboostingregressor_model.joblib'),\n",
       " ('MLPRegressor', 'mlpregressor_model.joblib')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Sauvegarder les 3 meilleurs modèles dans des fichiers .joblib\n",
    "top_3 = results_df.sort_values(by=\"R2 (test)\", ascending=False).head(3)\n",
    "\n",
    "saved_models = []\n",
    "for i, row in top_3.iterrows():\n",
    "    model_name = row[\"Modèle\"].lower().replace(\" \", \"_\")\n",
    "    filename = f\"{model_name}_model.joblib\"\n",
    "    joblib.dump(row[\"Pipeline\"], filename)\n",
    "    saved_models.append((row[\"Modèle\"], filename))\n",
    "\n",
    "saved_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
